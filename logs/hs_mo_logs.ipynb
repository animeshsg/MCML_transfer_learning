{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632da44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1307a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
    "# Then what you need from tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
    "# And pandas for data import + sklearn because you allways need sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49c3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'].to_pandas()\n",
    "print(\"Train dataset length:{}\".format(df.shape[0]))\n",
    "\n",
    "columns_list=['hatespeech',\n",
    " 'respect',\n",
    " 'insult',\n",
    " 'humiliate',\n",
    " 'status',\n",
    " 'dehumanize',\n",
    " 'violence',\n",
    " 'genocide',\n",
    " 'attack_defend']\n",
    "total_columns_list=['text']+columns_list\n",
    "df=df[total_columns_list]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
